{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech2Face.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniomuso/speech2face/blob/master/Speech2Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us6ergKlbJbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jXRWARmcebB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = \"/content/drive/My Drive/Speech2Face/vox\"\n",
        "# !curl --user voxceleb1912:0s42xuw6 -o \"/content/drive/My Drive/Speech2Face/ff/vox.zip\" http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXILePzTdsI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/drive/My Drive/Speech2Face/ff/vox.zip\" -d \"/content/drive/My Drive/Speech2Face/ff/ext/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBM5q_83fkuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meRq3GNUTrIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav, sr = librosa.load('/content/drive/My Drive/Speech2Face/vox1_dataset/vox_audios/ext/wav/id10270/5sJomL_D0_g/00001.wav',sr = 16000, duration = 6.0 ,mono = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqNwvJpU1pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spectro = librosa.core.stft(wav, n_fft = 512, hop_length = int(np.ceil(0.01 * sr)),win_length = int(np.ceil(0.025 * sr)) , window='hann', center=True,pad_mode='reflect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZCVSaO-VHau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust(stft):\n",
        "  if stft.shape[1] == 601:\n",
        "    return stft\n",
        "  else:\n",
        "    return np.concatenate((stft,stft[:,0:601 - stft.shape[1]]),axis = 1)\n",
        "\n",
        "spectroComplex = adjust(spectro)\n",
        "converted = np.zeros((spectroComplex.shape[0], spectroComplex.shape[1], 2))\n",
        "i = np.arange(spectroComplex.shape[0])\n",
        "j = np.arange(spectroComplex.shape[1])\n",
        "\n",
        "converted[i,j[:,np.newaxis], 0] = spectroComplex[i,j[:,np.newaxis]].real\n",
        "converted[i,j[:,np.newaxis], 1] = spectroComplex[i,j[:,np.newaxis]].imag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5sDbBkIa7Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SpeechEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SpeechEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 64, kernel_size=4,stride=1) \n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=4,stride=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=4,stride=1) \n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=4,stride=1) \n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))\n",
        "        self.conv5 = nn.Conv2d(128, 128, kernel_size=4,stride=1) \n",
        "        self.pooling3 = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))\n",
        "        self.conv6 = nn.Conv2d(128, 256, kernel_size=4,stride=1) \n",
        "        self.pooling4 = nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))\n",
        "        self.conv7 = nn.Conv2d(256, 512, kernel_size=4,stride=1) \n",
        "        self.conv8 = nn.Conv2d(512, 512, kernel_size=4,stride=2) \n",
        "\n",
        "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3,stride=2) # Queste due celle sono diverse\n",
        "        self.pooling5 = nn.AvgPool2d(kernel_size=(1,1), stride=1)# Queste due celle sono diverse\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 1 * 144, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm5 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm6 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm7 = nn.BatchNorm2d(512)\n",
        "        self.batch_norm8 = nn.BatchNorm2d(512)\n",
        "        self.batch_norm9 = nn.BatchNorm2d(512)\n",
        "      \n",
        "\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.batch_norm1(self.relu(self.conv1(x)))\n",
        "        out = self.batch_norm2(self.relu(self.conv2(out)))\n",
        "        out = self.batch_norm3(self.relu(self.conv3(out)))\n",
        "        out = self.pooling1(out)\n",
        "        out = self.batch_norm4(self.relu(self.conv4(out)))\n",
        "        out = self.pooling2(out)\n",
        "        out = self.batch_norm5(self.relu(self.conv5(out)))\n",
        "        out = self.pooling3(out)\n",
        "        out = self.batch_norm6(self.relu(self.conv6(out)))\n",
        "        out = self.pooling4(out)\n",
        "        out = self.batch_norm7(self.relu(self.conv7(out)))\n",
        "        out = self.batch_norm8(self.relu(self.conv8(out)))\n",
        "        out = self.batch_norm9(self.relu(self.pooling5(self.conv9(out))))\n",
        "\n",
        "        batch = out.shape[0]\n",
        "        out = out.view((batch, 512 * 1 * 144))\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVgjwV0dHL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SpeechEncoder()\n",
        "input = torch.unsqueeze(torch.tensor(converted).reshape(2,257,601), 0)\n",
        "\n",
        "model(input.type(torch.float32)).shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}